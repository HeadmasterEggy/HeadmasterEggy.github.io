<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="https://images-a2q.pages.dev/file/b89bbe01d52ee39e69cd8.png">
  <link rel="icon" type="image/png" sizes="32x32" href="https://images-a2q.pages.dev/file/b89bbe01d52ee39e69cd8.png">
  <link rel="icon" type="image/png" sizes="16x16" href="https://images-a2q.pages.dev/file/b89bbe01d52ee39e69cd8.png">
  <link rel="mask-icon" href="https://images-a2q.pages.dev/file/b89bbe01d52ee39e69cd8.png" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300italic,400,400italic,700,700italic%7CGrand+Hotel:300,300italic,400,400italic,700,700italic%7CUbuntu:300,300italic,400,400italic,700,700italic%7CJetBrains+Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.28/fancybox/fancybox.css" integrity="sha256-6cQIC71/iBIYXFK+0RHAvwmjwWzkWd+r7v/BX3/vZDc=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.19.1","exturl":true,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="The essay reviews methods for analyzing sentiments tied to specific aspects or features of entities, such as product components. It introduces Aspect-Based Sentiment Classification (ABSC), a fine-grai">
<meta property="og:type" content="article">
<meta property="og:title" content="A Survey on Aspect-Based Sentiment Classification">
<meta property="og:url" content="http://example.com/posts/cc20b26.html">
<meta property="og:site_name" content="Joey">
<meta property="og:description" content="The essay reviews methods for analyzing sentiments tied to specific aspects or features of entities, such as product components. It introduces Aspect-Based Sentiment Classification (ABSC), a fine-grai">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-10-10T08:26:21.000Z">
<meta property="article:modified_time" content="2024-12-02T14:11:37.637Z">
<meta property="article:author" content="Joey">
<meta property="article:tag" content="deepLearning">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/posts/cc20b26.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/posts/cc20b26.html","path":"posts/cc20b26.html","title":"A Survey on Aspect-Based Sentiment Classification"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>A Survey on Aspect-Based Sentiment Classification | Joey</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Joey</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">6</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">7</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">32</span></a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B3%E4%BA%8E%E5%9F%BA%E4%BA%8E%E6%96%B9%E9%9D%A2%E7%9A%84%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB%E7%9A%84%E7%BB%BC%E8%BF%B0"><span class="nav-text">关于基于方面的情感分类的综述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-text">摘要</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CCS%E6%A6%82%E5%BF%B5"><span class="nav-text">CCS概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%99%84%E5%8A%A0%E5%85%B3%E9%94%AE%E8%AF%8D%E4%B8%8E%E7%9F%AD%E8%AF%AD"><span class="nav-text">附加关键词与短语</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%BE%93%E5%85%A5%E8%A1%A8%E7%A4%BA"><span class="nav-text">输入表示</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#context"><span class="nav-text">context</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BB%B4%E5%BA%A6%E6%80%A7"><span class="nav-text">维度性</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E7%B1%BB%E5%9E%8B"><span class="nav-text">特征类型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E8%A1%A8%E7%8E%B0%E8%AF%84%E4%BC%B0"><span class="nav-text">3. 表现评估</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB"><span class="nav-text">4. 情感分类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-knowledge-based"><span class="nav-text">4.1 knowledge-based</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-1-Dictionary-Based"><span class="nav-text">4.1.1 Dictionary-Based</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-2-Ontology-Based"><span class="nav-text">4.1.2 Ontology-Based</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-3-Discourse-Based"><span class="nav-text">4.1.3 Discourse-Based</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-Machine-Learning"><span class="nav-text">4.2 Machine Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-Support-Vector-Machines"><span class="nav-text">4.2.1 Support Vector Machines</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-2-Tree-Based"><span class="nav-text">4.2.2 Tree-Based</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-3-Deep-Learning"><span class="nav-text">4.2.3 Deep Learning</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Joey"
      src="https://images-a2q.pages.dev/file/b89bbe01d52ee39e69cd8.png">
  <p class="site-author-name" itemprop="name">Joey</p>
  <div class="site-description" itemprop="description">A Humble Apprentice</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0hlYWRtYXN0ZXJFZ2d5" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;HeadmasterEggy"><i class="fab fa-github fa-fw"></i></span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOmhlYWRtYXN0ZXJlZ2d5QGdtYWlsLmNvbQ==" title="E-Mail → mailto:headmastereggy@gmail.com"><i class="fa fa-envelope fa-fw"></i></span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9IZWFkbWFzdGVyRWdneQ==" title="X → https:&#x2F;&#x2F;twitter.com&#x2F;HeadmasterEggy"><i class="fab fa-x-twitter fa-fw"></i></span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9pbnN0YWdyYW0uY29tL2VnZ3lvbGRnb29zZQ==" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;eggyoldgoose"><i class="fab fa-instagram fa-fw"></i></span>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/cc20b26.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://images-a2q.pages.dev/file/b89bbe01d52ee39e69cd8.png">
      <meta itemprop="name" content="Joey">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Joey">
      <meta itemprop="description" content="A Humble Apprentice">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="A Survey on Aspect-Based Sentiment Classification | Joey">
      <meta itemprop="description" content="The essay reviews methods for analyzing sentiments tied to specific aspects or features of entities, such as product components. It introduces Aspect-Based Sentiment Classification (ABSC), a fine-grained approach to sentiment analysis that focuses on identifying and classifying sentiments about specific aspects. The paper categorizes ABSC models into three groups: knowledge-based models, machine learning models (including SVMs and deep learning), and hybrid approaches that combine both.The essay also discusses key challenges, such as handling implicit aspects, processing sentences with multiple aspects, and dealing with complex language structures. Recent advances in deep learning and transformer models are highlighted as major contributors to improving performance in ABSC tasks. Finally, the essay points to future directions, suggesting a focus on better aspect detection, handling implicit aspects more effectively, and improving the scalability of ABSC models.">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          A Survey on Aspect-Based Sentiment Classification
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-10 16:26:21" itemprop="dateCreated datePublished" datetime="2024-10-10T16:26:21+08:00">2024-10-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-12-02 22:11:37" itemprop="dateModified" datetime="2024-12-02T22:11:37+08:00">2024-12-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>14k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>51 mins.</span>
    </span>
</div>

            <div class="post-description">The essay reviews methods for analyzing sentiments tied to specific aspects or features of entities, such as product components. It introduces Aspect-Based Sentiment Classification (ABSC), a fine-grained approach to sentiment analysis that focuses on identifying and classifying sentiments about specific aspects. The paper categorizes ABSC models into three groups: knowledge-based models, machine learning models (including SVMs and deep learning), and hybrid approaches that combine both.The essay also discusses key challenges, such as handling implicit aspects, processing sentences with multiple aspects, and dealing with complex language structures. Recent advances in deep learning and transformer models are highlighted as major contributors to improving performance in ABSC tasks. Finally, the essay points to future directions, suggesting a focus on better aspect detection, handling implicit aspects more effectively, and improving the scalability of ABSC models.</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="关于基于方面的情感分类的综述"><a href="#关于基于方面的情感分类的综述" class="headerlink" title="关于基于方面的情感分类的综述"></a>关于基于方面的情感分类的综述</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>随着互联网上评论和其他带有情感的信息文本数量的不断增长，自动情感分析算法的需求持续上升。基于方面的情感分类（Aspect-Based Sentiment Classification, ABSC）能够从文本文档或句子中自动提取极为细粒度的情感信息。这篇综述总结了ABSC研究的快速发展状态，并提出了一种新颖的分类法，将ABSC模型分为三大类：基于知识的方法、机器学习模型和混合模型。文中不仅提供了这些模型性能的总结概览，还对各种ABSC模型进行了技术性和直观性的解释。</p>
<p>本文讨论了当前最先进的ABSC模型，例如基于Transformer模型的模型和结合知识库的混合深度学习模型。此外，还回顾了各种模型输入表示与输出评估的技术。文章进一步探讨了ABSC研究的趋势，并就未来如何推进该领域发展提出了讨论。</p>
<h3 id="CCS概念"><a href="#CCS概念" class="headerlink" title="CCS概念"></a>CCS概念</h3><p>• <strong>信息系统</strong> → 情感分析；数据挖掘</p>
<p>• <strong>计算方法</strong> → 机器学习</p>
<h3 id="附加关键词与短语"><a href="#附加关键词与短语" class="headerlink" title="附加关键词与短语"></a>附加关键词与短语</h3><p>基于方面的情感分类、基于知识的模型、深度学习、注意力模型、混合模型</p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>万维网为人们通过各种基于文本的渠道（如在线评论和社交媒体）在线分享意见提供了途径。能够利用这些意见准确评估人们对某一产品、人物或地点的看法，在许多行业中都具有极高的价值。餐厅可以根据在线食品评论调整菜单，公司可以根据消费者的具体需求改进产品，政治活动的效果也可以通过分析社交媒体帖子来评估。因此，随着互联网的兴起，情感分析这一任务变得越来越重要【149】。</p>
<p>情感分析是一项从文本中提取并分析人们对特定实体的情感的任务【118】。在文献中，情感分析有时也被称为“观点挖掘”。然而，需要区分“情感”（sentiments）和“观点”（opinions）。具体来说，“观点”表示某人对某一特定问题的看法，而“情感”则反映某人对某事物的感受。不过，这两个概念高度相关，通常可以通过“观点词”来提取情感【94, 95】。 在情感分析中，目标是根据文本内容分配情感极性。尽管“极性”（polarity）和“情感”（sentiment）这两个术语经常被互换使用，但实际上它们之间也可以进行区分：情感指代一种感受，而极性则表达一种方向性（例如，“正面”、“中性”或“负面”）。情感分析任务的粒度可以通过三个独立的特征来描述：情感类型、任务层次和任务目标。首先，情感输出的类型需要被明确。例如，该任务可能涉及简单的二元分类（“正面”或“负面”标签），但也可能包括其他标签（如“中性”），甚至需要预测情感的强度或分值。<br>其次，任务层次决定了从文本中提取情感的层级。例如，在文档级别的情感分析中，情感是针对整个文档进行分析的；而在句子级别的情感分析中，情感是针对文档中的每一个句子进行分析的。此外，还有许多其他层级，例如单词、段落、句子组或文本片段。最后，任务目标决定了情感的焦点。某些情况下可能不存在情感目标，这意味着任务是为整个文本分配一个情感分数或标签。而在其他情况下，可能需要了解针对文本中特定主题、实体或方面的情感。例如，假设我们在分析一篇产品评论。如果未定义目标，我们仅考虑整篇文本的情感。然而，明确消费者对产品的哪些具体方面感到满意或不满可能会更有用，因为这提供了许多应用所需的详细信息【115】。在文本中识别这些方面并分析其情感的任务被称为基于方面的情感分析（Aspect-Based Sentiment Analysis, ABSA）。</p>
<p>ABSA 是一个相对较新的研究领域，由于其广泛的应用价值而迅速获得了极高的关注【32】。然而，ABSA 和一般的情感分析任务一样，具有较高的难度，这主要源于句子结构和写作风格的多样性【174】。[143] 对 ABSA 中存在的问题和挑战进行了全面概述。与一般的情感分析任务类似，ABSA 可以在多个层次上执行，其中文档级和句子级通常是最受欢迎的【157】。文档级 ABSA 方法侧重于识别文档中与某一实体相关的一般方面，并为其分配情感。相比之下，句子级 ABSA 方法尝试逐句识别所有方面，确定这些方面相关的情感，并可能在评论层面聚合情感【157】。因此，文档级 ABSA 考虑的是总结文本情感的一般概念，而句子级 ABSA 则关注单独提及的各个方面。ABSA 的任务可以进一步分为三个子任务：<strong>方面检测&#x2F;提取</strong>、<strong>情感分类</strong>和<strong>情感聚合</strong>【174】。方面提取的任务是识别文本中存在的方面；分类步骤是为提取的方面分配情感标签或评分；聚合步骤则是汇总方面的情感分类结果。在本次综述中，我们的重点是情感分类步骤，这通常被称为<strong>基于方面的情感分类（Aspect-Based Sentiment Classification, ABSC）</strong>。</p>
<p>关于 ABSA 的各种综述已经发表【152, 174】。然而，专注于 ABSC 的综述似乎能够更有效地深入讨论和评估 ABSC 模型。目前唯一专门针对 ABSC 的综述是文献【230】，其提供了对深度学习技术的概览。尽管深度学习模型目前是 ABSC 的最先进方法，但我们认为，扩展研究范围可以更有效地评估 ABSC 研究的当前状态和未来发展。例如，ABSC 中的一个重要部分是将知识库引入分类模型的相关研究。此外，之前的综述中缺少了一些重要的深度学习模型，例如基于 Transformer 的模型【201】。</p>
<p>基于上述原因，本综述提供了关于当前最先进的 ABSC 模型的全面概览。为此，我们提出了一种文献中尚未出现的 ABSC 模型新分类法。该分类法将 ABSC 模型划分为三大类别：<strong>基于知识的方法</strong>、<strong>机器学习模型</strong>和<strong>混合模型</strong>。基于这一分类结构，我们使用技术性和直观性的解释讨论并比较了不同 ABSC 模型的架构。此外，我们还提供了比以往综述更大范围的 ABSC 模型性能总结概览。最后，我们识别了 ABSC 研究中的趋势，并利用这些发现讨论了推进该领域未来发展的可能途径。</p>
<p>本综述的章节安排基于设计 ABSC 方法时的主要步骤。</p>
<p>• <strong>第 2 章</strong> 讨论 ABSC 输入表示的不同方法。</p>
<p>• <strong>第 3 章</strong> 回顾了用于评估模型性能的技术。</p>
<p>• <strong>第 4 章</strong> 根据提出的分类法介绍了各种 ABSC 模型，讨论了这些模型如何利用预处理后的输入生成所需的分类输出，并比较了文献中不同模型的性能。</p>
<p>• <strong>第 5 章</strong> 探讨了与 ABSC 相关的其他主题。</p>
<p>• <strong>第 6 章</strong> 总结了主要内容，并讨论了未来研究的发展方向。</p>
<h1 id="输入表示"><a href="#输入表示" class="headerlink" title="输入表示"></a>输入表示</h1><p>在本章中，将详细解释 ABSC 所需的输入表示。我们首先根据 Schouten 和 Frasincar 的定义【174】引入一些定义。给定包含记录 $R_1, R_2, \dots, R_{n_R}$ 的语料库 $C$，ABSA 可以被形式化为在每条记录 $R_j$ 中找到所有四元组 $(y, a, h, t)$【118】，其中 $y$ 表示情感，$a$ 表示情感的目标方面，$h$ 表示情感的表达者，$t$ 表示情感的表达时间【174】。一条记录被定义为语料库中的一段文本，可能是一个短语、一句话或一篇较大的文本，例如一篇文档。</p>
<p>通常，大多数方法关注的是查找 $(y, a)$，即目标方面及其对应的情感。由于本综述仅关注 ABSA 的分类步骤，因此假设文本中目标方面 $a$ 已经被识别。因此，ABSC 模型仅专注于寻找与给定方面 $a$ 对应的情感 $y$。例如，考虑一条形式为餐厅评论的记录：“The atmosphere was fantastic, but the food was bland.”这句话包含两个方面“atmosphere”和“food”，我们假设这些方面已在先前的方面提取阶段被识别。最终目标是利用 ABSC 模型为这些方面确定情感分类。在此示例中，正确的情感分别为“positive”和“negative”。</p>
<p>然而，在尝试这一任务之前，必须构建输入表示，因为文本通常不能直接用作分类模型的输入。方面及其对应的上下文必须通过数值特征进行表示。需要注意的是，在基于方面或特征的情感分析中，“特征”一词有时被用来描述例如产品的各个方面。然而，在此上下文中，“特征”指的并不是方面本身，而是数据的特征。在实现 ABSC 模型之前，需要一个预处理阶段来构建数值表示【70, 80】。用于输入的特征是分类过程中的关键部分，因为它们决定了 ABSC 模型可访问的信息量。在保证不包含冗余或无关特征的情况下，重要的是以一种尽可能多地保留信息的方式表示文本，以便模型可以最佳地执行。</p>
<p>ABSC 的输入表示通常由三个特性组成：<strong>上下文、维度性和特征类型</strong>。我们将在 2.1 节、2.2 节和 2.3 节分别讨论这些特性。</p>
<h1 id="context"><a href="#context" class="headerlink" title="context"></a>context</h1><p>给定一条记录 $R_j$，我们将上下文定义为被视为输入的一部分单词子集。如果文本仅包含一个方面，则可以选择简单地考虑所有单词。然而，如果记录中包含多个方面，则需要为每个方面单独开发一种表示方法，例如，为每个方面提取一部分单词。</p>
<p>输入表示方法根据文本中是否存在目标短语（Target Phrase）而有所不同。因此，我们将输入表示技术分为<strong>显式方面</strong>和<strong>隐式方面</strong>两种情况。</p>
<p><strong>显式方面</strong></p>
<p>显式方面通常是最常见的类型。例如，在评论句子“The price of this phone is very high.”中，方面被明确表述为“price”。确定这种显式方面的上下文最简单的方法是围绕目标短语使用一个窗口，仅基于窗口中的单词构建输入表示。例如，Guha 等人【77】仅考虑方面本身、方面左侧的三个单词以及右侧的三个单词。然而，这种基于物理邻近性的简单方法可能并不理想，因为表达情感的单词可能距离方面较远。因此，更健壮的方法不会依赖单词之间的物理距离。例如，可以使用语法依赖关系（Grammatical Dependencies）来确定记录中与方面相关的单词，并将这些单词纳入上下文【193】。另一种方法是使用文本核（Text Kernels），通过单词之间的关系表达距离。例如，Nguyen 和 Shirai【144】使用树核（Tree Kernels）进行关系提取，以确定在分析中考虑哪些单词。</p>
<p><strong>隐式方面</strong></p>
<p>隐式方面的一个例子是“This phone is really expensive.”，其中方面仍是“price”，但方面未在文本中直接提及。由于没有目标短语来定义窗口中心或确定单词的距离，隐式方面的处理需要不同的方法。如果假设记录中仅包含一个方面，例如上述例子，则可以简单地将整个句子视为输入表示。然而，正如 Dosoula 等人【52】所述，评论中通常包含多个隐式方面，甚至可能出现在同一句中。例如，之前的例子可以扩展为：“This phone is really expensive, but also very fast.”。此时，句中有两个隐式方面。Dosoula 等人【52】提出了基于方面代理词（Aspect Proxy Words）的不同方法来确定句子中每个方面的上下文。</p>
<h1 id="维度性"><a href="#维度性" class="headerlink" title="维度性"></a>维度性</h1><p>输入表示的维度性直接由后续情感分类步骤中使用的模型类型决定。一些模型（例如支持向量机和决策树）只能处理单一向量表示，而其他模型（例如循环神经网络）则可以处理一组向量或数据矩阵。</p>
<p>假设记录 $R_j$ 包含一个方面，我们希望用数值特征表示整个记录。根据所使用的 ABSC 模型，记录 $R_j$ 可以表示为单一向量 $\mathbf{x}_j \in \mathbb{R}^{d_x}$，或者表示为矩阵 $\mathbf{X}_j \in \mathbb{R}^{d_x \times n_j}$，其中 $d_x$ 表示用于表示的特征数，$n_j$ 表示记录 $R_j$ 中单词的数量。</p>
<p>• <strong>单一向量表示</strong>：将记录表示为一个嵌入向量，其中每个元素表示一个特征的存在，例如是否存在特定的情感词或短语。</p>
<p>• <strong>数据矩阵表示</strong>：提供更详细的信息，因为它无需将所有信息总结为一个向量。矩阵的每一列是一个嵌入向量，表示记录的一部分，例如一个句子、一个单词或一个字符。</p>
<p>输入的维度性通常会影响所使用的特征类型，因为某些特征类型更适合向量表示，而另一些则可以更有效地用于矩阵表示。下一节将对此进行更详细的讨论。</p>
<h1 id="特征类型"><a href="#特征类型" class="headerlink" title="特征类型"></a>特征类型</h1><p>在将文本表示为单一向量时，可以使用传统的文本分类特征类型。其中最简单且最常用的方法之一是<strong>词袋模型</strong>（Bag-of-Words, BoW）表示。BoW 表示是一种特征向量，其中每个元素代表一个单词。这种表示被称为“袋子”，是因为我们简单地将单词汇集在一起，而忽略了文本的结构。例如，假设我们希望使用单一向量 $\mathbf{x}<em>j$ 表示记录 $R_j$，首先需要构建一个词汇表，该词汇表包含语料库 $C$ 中每条记录中所有使用过的唯一单词。对于 BoW 表示，向量 $\mathbf{x}j$ 中的每个元素 $x{i,j}$ 对应于词汇表中的一个唯一单词。最简单的 BoW 向量是一个二值向量，其中，如果对应的单词出现在 $R_j$ 中，则 $x</em>{i,j} &#x3D; 1$，否则 $x_{i,j} &#x3D; 0$。</p>
<p>一种更常用的版本是考虑单词的频率，通过将向量 $\mathbf{x}<em>j$ 中的每个元素 $x</em>{i,j}$ 设置为对应单词在 $R_j$ 中出现的次数【169】。然而，一些单词的使用频率本身较高，这可能导致单词计数中对某些单词的偏倚。因此，可以选择使用<strong>词频-逆文档频率</strong>（Term Frequency-Inverse Document Frequency, TF-IDF）方法【103】来替代直接的单词计数。该方法本质上是记录中单词的频率与其在所有记录中出现频率的缩放比例。对于词汇表中的单词 $w_i$，TF-IDF 可通过以下公式计算：</p>
<p>$$x_{i,j} &#x3D; \frac{n_{i,j}}{n_j} \times \log \frac{n_R}{|{R_j \in C : w_i \in R_j}|}$$<br>其中：</p>
<p>• $n_{i,j}$ 表示单词 $w_i$ 在记录 $R_j$ 中出现的次数，</p>
<p>• $n_j$ 表示记录 $R_j$ 中的单词总数，</p>
<p>• $n_R$ 表示记录的总数，</p>
<p>• $C$ 表示记录的集合。</p>
<p>正如前文所述，在 ABSC 中，当记录中存在多个方面时，最好不要使用单一的文本表示。因此，可以仅基于被视为上下文中的单词创建一个词袋（BoW）表示。</p>
<p>BoW 特征在 ABSC 中表现良好，但可能会引发一些使分类过程变得困难的问题。首先，大型语料库可能包含大量不同的单词，这意味着如果每个单词都用一个元素表示，词汇表及其对应的特征向量将会非常庞大。因此，开发了一些方法来选择可用作特征的最重要单词。例如，可以基于列表或词典过滤掉通常不具有实际意义或语义价值的单词，如停用词。尽管这些技术可以显著减少特征数量，但向量通常仍然较大。因此，ABSC 模型的一个重要特性是需要能够很好地处理高维向量，这将在第 4 章中更详细地讨论。</p>
<p>其次，如前文所述，BoW 完全忽略了单词的结构，使得难以捕捉方面与其上下文之间的关系。一种解决方法是引入 n-grams，但这会进一步加剧前述的高维性问题。另一种解决方案是包括定义单词之间关系的特征。通常会使用其他形式的特征类型，以包含不同类型的信息。例如，Al-Smadi 等人【6】在 TF-IDF BoW 表示的基础上增强了形态学、句法和语义特征。类似地，Mullen 和 Collier【141】实现了语义、句法和基于邻近性的特征。表 1 概述了各种特征类型及其对应的示例。</p>
<table>
<thead>
<tr>
<th><strong>特征类型 (Feature Types)</strong></th>
<th><strong>特征示例 (Feature Examples)</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>单词特征 (Word Features)</strong></td>
<td>词袋（Bag-of-Words）【177】，词嵌入（Word Embeddings）【132】，n-grams【148】</td>
</tr>
<tr>
<td><strong>句法特征 (Syntactic Features)</strong></td>
<td>词性标注（Part-of-Speech Tagging）【54, 162】，依存分析（Dependency Parsing）【54, 111, 140, 173】</td>
</tr>
<tr>
<td><strong>基于邻近的特征 (Proximity-Based Features)</strong></td>
<td>相对于情感词【82, 141】或目标词【100】的邻近性</td>
</tr>
<tr>
<td><strong>语义特征 (Semantic Features)</strong></td>
<td>上下文词的情感得分（Sentiment Scores of Context Words）【83, 198】</td>
</tr>
<tr>
<td><strong>形态学特征 (Morphological Features)</strong></td>
<td>词元（Lexemes）和词形（Lemmas）【1, 6, 173】</td>
</tr>
</tbody></table>
<p>假设我们现在希望用矩阵 $\mathbf{X}_j$ 表示记录 $R_j$。在这种情况下，想法是将文本中的每个单词表示为一个向量，并将其存储为 $\mathbf{X}_j$ 中的一列。一种标准选择是使用词嵌入。关于各种类型的词嵌入，可以参考文献【27】。一些示例包括：GloVe【153】、fastText【73】和 Word2Vec【133】。这些嵌入类型都尝试使用有限大小的向量表示单词的意义。</p>
<p>虽然经常使用预训练的词嵌入，但也可以在 ABSC 模型训练过程中同时训练词嵌入。此外，上述嵌入模型都是非上下文的，这意味着每个单词的嵌入是独立于其他单词生成的。然而，众所周知，一个单词的意义可能会根据其使用的上下文而变化。因此，另一种解决方案是使用上下文相关的词嵌入，例如基于 ELMo【154】或 BERT【48】的嵌入。这些词嵌入模型会根据周围上下文为单词生成不同的向量。例如，单词“playing”在“playing tennis”和“playing piano”中的含义不同，因此会被分配不同的词嵌入。 </p>
<p>此外，还有专门为情感分析设计的词嵌入【189】。尽管词嵌入本身是一个强大的表示工具，但仍可以添加额外的特征类型，例如表 1 中的示例。例如，文献【7】将词嵌入与句法和语义特征结合使用。本节讨论的输入表示是第 4 章中分类模型的基础。在本文的其余部分，我们假设输入表示已经预先构建完毕。仅当分类模型对输入表示进行了修改时，我们才会进一步阐述输入表示。此外，为了清晰起见，本文其余部分不使用特定于记录或方面的下标。</p>
<h1 id="3-表现评估"><a href="#3-表现评估" class="headerlink" title="3. 表现评估"></a>3. 表现评估</h1><p>ABSC 模型的目标是利用输入表示生成输出。因此，给定包含方面 $a$ 的记录 $R$，ABSC 模型使用特征向量 $\mathbf{x} \in \mathbb{R}^{d_x}$ 或矩阵 $\mathbf{X} \in \mathbb{R}^{d_x \times n_x}$ 生成一个标签 $\hat{y} \in \mathbb{R}^1$，其中 $d_x$ 表示使用的特征数量，$n_x$ 表示被视为上下文的单词数量。</p>
<p>可以通过评估输出 $\hat{y}$ 使用多种性能指标来比较 ABSC 模型的有效性。这些指标突出显示了分类模型的某些优点和缺点。本节介绍了用于评估 ABSC 模型的各种技术。这些指标将在第 4 章中用于比较和对比不同的 ABSC 方法。</p>
<p>ABSC 和 ABSA 中最常用的性能指标包括众所周知的准确率（Accuracy）、精确率（Precision）、召回率（Recall）和 F1 值【174】。这些指标通过将情感分类 $\hat{y}$ 与方面的真实情感标签 $y$ 进行比较来进行评估。达到高值的模型将提供更高质量的预测。</p>
<p>• <strong>准确率（Accuracy）</strong>：衡量正确分类的方面数量与数据集中方面总数的比率。这一指标直观清晰，是对模型预测能力的直接反映。在二分类场景中，一个简单的基线是随机分类器，其期望准确率为 $0.5$，任何预测模型都应优于这一水平。然而，在不平衡数据集中，准确率往往不是有效的性能指示器。如果一个数据集包含两个类别，其中 90% 的记录属于一个类别，则始终预测该类别可以得到高达 $0.9$ 的准确率。</p>
<p>• <strong>精确率和召回率（Precision and Recall）</strong>：为了解决不平衡数据集中的问题，使用了其他指标如精确率和召回率，这些指标提供了更有意义的分类性能评估。可以通过计算每个类别的精确率和召回率的均值（宏平均，Macro-Averaging）或根据所有类别的贡献进行聚合（微平均，Micro-Averaging）来获得模型性能的总体度量。</p>
<p>• <strong>F1 值（F1-Measure）</strong>：由于精确率和召回率关注模型性能的不同方面，F1 值通常用于总结这些信息。</p>
<p>类似的方法可以用于聚合来自多个不同数据集的结果。可以计算不同数据集性能指标的均值（宏平均），或者基于数据集的贡献进行聚合（微平均）。</p>
<p>本文讨论的大多数研究都使用了准确率（Accuracy）、精确率（Precision）、召回率（Recall）和 F1 值。然而，偶尔也会使用一些替代指标，例如均方误差（Mean Squared Error, MSE）和排序损失（Ranking Loss）。</p>
<p>假设我们有一个包含 $N$ 个特征向量 $\mathbf{x}_1, \dots, \mathbf{x}_N$ 的训练数据集，以及其对应的标签 $y_1, \dots, y_N$。每个特征向量 $\mathbf{x}_1, \dots, \mathbf{x}_N$ 表示记录中的一个方面及其相应的上下文（如第 2 章所述）。对应的标签 $y_1, \dots, y_N$ 表示针对这些方面表达的真实情感。通过 ABSC 模型，可以生成标签预测 $\hat{y}_1, \dots, \hat{y}_N$。</p>
<p>情感分析的标签通常被视为有序数据，均方误差（MSE）可按以下公式计算：</p>
<p>$$\text{MSE} &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N (\hat{y}_i - y_i)^2$$</p>
<p>由于平方的存在，MSE 对大误差的惩罚比小误差更大。一种替代方法是排序损失（Ranking Loss）【40】，它以更均等的方式惩罚大误差和小误差。排序损失与平均绝对误差密切相关，其公式如下：</p>
<p>$$\text{Ranking Loss} &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N |\hat{y}_i - y_i|$$</p>
<p>排序损失和 MSE 都用于衡量分类预测中的误差。因此，对于这些指标，值越低，模型性能越好。</p>
<p>另一种性能指标是接收者操作特性（ROC）曲线下面积，简称为 AUC。ROC 曲线绘制了召回率与真正率的关系。曲线下面积（AUC）反映了模型区分类别的能力，AUC 值越高，模型性能越好。</p>
<h1 id="4-情感分类"><a href="#4-情感分类" class="headerlink" title="4. 情感分类"></a>4. 情感分类</h1><p>ABSC 模型通常可以分为三大类：<strong>基于知识的方法</strong>、<strong>机器学习模型</strong>和<strong>混合模型</strong>。图 1 展示了包含这些类别及其子类别的分类法。这些分类的详细解释分别见 4.1、4.2 和 4.3 小节。每个小节中都包含对该类别主要 ABSC 模型的概述，并以总结表格的形式呈现。</p>
<p>每个表格包含以下列信息：</p>
<p>• 模型名称；</p>
<p>• 使用的数据类型；</p>
<p>• 每个模型报告的各种性能指标。</p>
<p>对于使用来自不同领域的数据集的模型，每一行可能包含多个条目。此外，我们还报告了其他研究中使用不同数据集对同一模型的实现结果。当模型在另一篇论文中被重新实现时，我们会在条目下方标明这一点。对于不可用的信息，以“-” 表示。</p>
<p>由于无法包含每篇论文报告的所有结果，我们采取了一些步骤对结果进行总结：</p>
<ol>
<li><p>仅包含每篇论文中提出的最佳模型架构的结果；</p>
</li>
<li><p>当在同一领域中使用多个数据集时，我们取这些数据集的平均结果。唯一的例外是当模型在另一篇论文中被重新实现时，因为无法保证模型的实现完全相同。</p>
</li>
</ol>
<p>为了便于模型比较，表格中列出了所有数据集的参考文献。一些 ABSC 数据集的一般特性见表 2。需要注意的是，此表仅包括列出数据集中最常用的领域和语言。例如，SemEval-2016 数据集包含许多其他语言，如荷兰语、中文和土耳其语。</p>
<h2 id="4-1-knowledge-based"><a href="#4-1-knowledge-based" class="headerlink" title="4.1 knowledge-based"></a>4.1 knowledge-based</h2><p>基于知识的方法（亦称符号人工智能）是利用知识库的技术。知识库通常被定义为包含信息的存储系统，并伴随有一组规则、关系和假设，计算机系统可以据此推理。基于知识的方法与输入表示密切相关，因为这些方法通常使用知识库来定义特征。</p>
<p>基于知识的方法的一个优势是其可解释性。具体而言，通常可以轻松识别用于生成模型输出的信息。基于知识的方法的底层机制通常相对简单，这使得 ABSC 的方法具有高度透明性。这些方法无需训练时间，但知识库的构建可能需要耗费大量时间。</p>
<p>我们讨论以下三种基于知识的方法：<strong>基于词典的方法</strong>、<strong>基于本体的方法</strong>和<strong>基于语篇的方法</strong>。各种基于知识的方法的性能见表 3。</p>
<p>![[图 1. ABSC 方法的分类体系。.png]]<br>Table 2. Overview of datasets used for ABSC.<br>![[Table 2. Overview of datasets used for ABSC..png]]</p>
<h3 id="4-1-1-Dictionary-Based"><a href="#4-1-1-Dictionary-Based" class="headerlink" title="4.1.1 Dictionary-Based"></a>4.1.1 Dictionary-Based</h3><p>早期的 ABSC 方法大多基于词典。给定包含一个方面 $a$ 的记录 $R$，基于词典的方法使用词典构建一个特征向量 $\mathbf{x}$，其中每个元素 $x_i$ 表示上下文中某个单词相对于该方面的情感得分或方向性。ABSC 可以使用多种词典，例如 WordNet【134】和 SentiWordNet【14】。这些词典定义了单词集合及其之间的语言关系。例如，WordNet【134】将名词、动词、形容词和副词分组为所谓的“同义集”（synsets），即同义词集合或具有相同意义的单词组。这些关系可以用于 ABSC，因为单词通常表现出与其同义词相同的情感【94】。</p>
<p>基于此方法，首先需要一组已知情感的种子单词。例如，可以使用“good”、“fantastic”和“perfect”作为正面种子单词，使用“bad”、“boring”和“ugly”作为负面种子单词。然后，可以利用词典（如 WordNet【134】）中定义的同义集，基于种子单词确定围绕某一方面的单词情感。与正面种子单词同义或与负面种子单词反义的单词将获得正面的情感得分。SentiWordNet【14】部分基于这种思想。该词典通过结合种子集扩展方法和多种分类模型，为每个同义集生成情感标签（“正面”、“中性”或“负面”）。</p>
<p>![[Table 3. Overview of prominent knowledge-based ABSC models and their reported performances..png]]<br>在为上下文单词确定情感得分后，需要实施一种方法来生成情感输出。例如，文献【94】的作者检查上下文中是否主要包含负面或正面单词。在【94】中，上下文单词的情感得分被编码为：正面为 1，负面为 -1，中性为 0。然后，通过对特征向量 $\mathbf{x}$ 的各元素求和来确定情感分类。如果总和为正，则返回正面标签；否则返回负面标签。</p>
<p>类似地，在文献【58】中，上下文单词被分配到 [-4, 4] 范围内的情感得分。然后，根据与方面相关的意见单词的平均得分来确定该方面的情感极性。</p>
<h3 id="4-1-2-Ontology-Based"><a href="#4-1-2-Ontology-Based" class="headerlink" title="4.1.2 Ontology-Based"></a>4.1.2 Ontology-Based</h3><p>基于本体的方法。本体通常被定义为“共享概念化的显式、可机器读取的规范”【74, 182】，其定义了一组对应于实体属性的实体和关系。本体与词典的主要区别在于，词典捕获的是单词之间的语言关系，而本体表示的是实际实体之间的关系。这些关系可以用于确定记录中哪些单词对确定方面的情感是重要的。</p>
<p>在 ABSC 中，可以使用现有的本体，也可以根据当前领域创建一个新的本体【108】。现有本体的示例包括语义互联网络社区（SIOC）本体【181】，该本体捕获了来自在线社区网站的数据，以及文献【165】中提出的情感本体。然而，与依赖现有本体相比，大多数研究者更倾向于创建自己的本体。这是因为很难找到一个与特定领域密切相关的现有本体，因为许多现有本体通常仅捕获通用概念。</p>
<p>本体设计通常使用特定方法，例如形式概念分析（Formal Concept Analysis）【147】或 OntoClean 方法论【76】。为了确保捕获关系的准确性，本体通常是手动创建的【131】。然而，这一过程非常耗时。因此，在创建大型本体时，半自动甚至完全自动化的本体创建方法变得至关重要。例如，文献【38】中提出了一种语义资产管理工作台（SAMW），用于半自动创建 ABSC 的本体。而文献【8】则提出了一种完全自动化创建本体的方法。</p>
<p>本体捕获了某一领域中对象的结构。这些关系可用于确定与某一方面相关的上下文【108】。然后，可以利用基于本体获取的上下文通过某种方法确定情感标签，例如使用基于词典的情感分类器【231】。</p>
<p>尽管常规本体是定义对象之间关系的有用工具，但为了进一步支持情感分析，可以将情感信息整合到本体中。这类情感本体专门定义单词或实体之间的情感关系。例如，在文献【146】中，构建了一种情感本体树，将产品方面与对应情感得分的意见词连接起来。在文献【215】中，利用 SentiWordNet 词典【14】定义情感关系构建了情感本体。Zhuang 等人【235】提出了一种针对 ABSA 的半自动本体构建方法，根据情感关系构建本体。</p>
<p>在对某一方面进行分类时，可以将上下文中的单词链接到情感本体中的概念和关系，并总结情感关系以生成情感分类。文献【235】提出的半自动方法主要关注单词频率，因为领域数据量有限。在文献【46】中，提出了另一种基于 WordNet【134】词典的同义集（synsets）的半自动本体构建方法。最后，ten Haaf 等人【190】提出了一种基于 word2vec【133】方法生成的词嵌入的半自动本体构建方法。</p>
<h3 id="4-1-3-Discourse-Based"><a href="#4-1-3-Discourse-Based" class="headerlink" title="4.1.3 Discourse-Based"></a>4.1.3 Discourse-Based</h3><p><strong>基于语篇的方法</strong>。另一种可用于 ABSC 的知识库是基于<strong>修辞结构理论</strong>（Rhetorical Structure Theory, RST）构建的语篇树【128】。RST 可用于在记录中定义一个层次化的语篇结构，将短语分类为基本语篇单元（Elementary Discourse Units, EDU）。与本体类似，语篇树定义了一组关系，这些关系可用于确定在为某一方面分配情感分类时哪些单词是重要的。</p>
<p>对于记录 $R$，可以构建一个语篇树以定义记录中的层次化语篇关系。为了确定记录中某一方面 $a$ 的上下文，文献【91】的作者提出了一种基于 RST 的方法，该方法生成一棵语篇树的子树，包含与方面直接相关的语篇关系。这棵子树被称为<strong>上下文树</strong>（context tree），可以用来确定该方面的情感分类。</p>
<p>由于上下文树本身不包含任何情感信息，文献【91】中的作者使用了一种基于词典的方法，为上下文树的叶节点分配句子级 ABSC 的情感方向得分。然后，可以通过求上下文树中定义的情感得分的总和来确定方面的情感分类。在文献【170】中，采用了类似的技术，但使用了更复杂的得分聚合方法。</p>
<p>除了 RST 之外，还有其他类型的语篇结构理论【93】。例如，<strong>跨文档结构理论</strong>（Cross-Document Structure Theory, CST）【160】可用于分析文档组之间的结构和语篇关系。跨文档结构分析在社交媒体分析中非常有用，因为社交媒体帖子通常是短文档，且彼此高度关联。一个有趣的示例是 SMACk 系统【53】，该系统基于抽象论证理论【56】分析跨文档结构。例如，某一产品可能会收到来自不同用户的多条评论，这些评论可能相互回应。SMACk 系统分析评论中提出的不同论点之间的关系，从而改进针对不同方面表达的情感聚合【54】。</p>
<h2 id="4-2-Machine-Learning"><a href="#4-2-Machine-Learning" class="headerlink" title="4.2 Machine Learning"></a>4.2 Machine Learning</h2><p>与利用知识库实现情感分类的基于知识的方法不同，机器学习模型（亦称为次符号人工智能，subsymbolic AI）使用包含特征向量及其对应正确标签的训练数据集。机器学习模型通过训练从数据中提取可用于区分情感类别的模式。机器学习模型种类繁多，可以分为以下几类：<strong>支持向量机（Support Vector Machines）</strong>、<strong>基于树的模型（Tree-Based Models）</strong>、<strong>深度学习模型（Deep Learning Models）以及基于注意力的深度学习模型（Attention-Based Deep Learning Models）</strong>。各种机器学习模型的性能表现见表 4。</p>
<p>![[Table 4. Overview of prominent machine learning ABSC models and their reported performances..png]]</p>
<h3 id="4-2-1-Support-Vector-Machines"><a href="#4-2-1-Support-Vector-Machines" class="headerlink" title="4.2.1 Support Vector Machines"></a>4.2.1 Support Vector Machines</h3><p>支持向量机（SVM）模型【39】长期以来一直是情感分析和 ABSC 的热门选择【7, 141, 150, 151, 200】。SVM 模型通过构造一个超平面，将属于不同类别的数据向量分离开来，从而实现分类【26, 39, 200】。在 ABSC 的场景中，这相当于基于特征向量 $\mathbf{x}$ 将方面分为情感类别（“正面”、“中性”和“负面”）。</p>
<p>假设我们有一个包含 $N$ 个特征向量 $\mathbf{x}_1, \dots, \mathbf{x}_N$ 的训练数据集，以及其对应的标签 $y_1, \dots, y_N$。每个特征向量 $\mathbf{x}_1, \dots, \mathbf{x}_N$ 表示记录中的一个方面及其上下文（如第 2 章所述）。对应的标签 $y_1, \dots, y_N$ 表示针对这些方面表达的真实情感。</p>
<p>我们首先考虑只有两个情感类别的情况：“正面”和“负面”。对于表达正面情感的方面，其标签被编码为 1；对于表达负面情感的方面，其标签被编码为 -1。SVM 分类器可以总结为以下公式：</p>
<p>$$\hat{y} &#x3D; \text{sign}(\mathbf{w}^T \cdot \phi(\mathbf{x}) + b)$$</p>
<p>其中：</p>
<p>• $\mathbf{w}$ 表示权重向量，</p>
<p>• $\phi(\mathbf{x})$ 表示特征映射函数，</p>
<p>• $b$ 表示偏置项，</p>
<p>• $\hat{y}$ 表示预测标签。</p>
<p>其中，$\mathbf{w} \in \mathbb{R}^{d_x}$ 是学习得到的权重向量，$b \in \mathbb{R}^1$ 是学习得到的偏置常数。权重的确定是通过构造一个超平面来完成的，该超平面最大化了训练数据标签 $y_1, \dots, y_N$ 和特征向量 $\mathbf{x}_1, \dots, \mathbf{x}_N$ 之间的分离。虽然一些数据集可以通过线性函数形式分离，但其他问题可能无法如此轻松地解决。在这种情况下，可以使用核函数 $\phi()$ 将特征向量 $\mathbf{x}$ 转换到更高维空间，从而使标签更容易分离【171】。然而，使用核函数的一个缺点是，由于非线性，学习到的系数变得难以解释。当需要将某一方面分类为多个情感类别时，必须调整 SVM 模型。例如，可以使用“一对多”实现（one-versus-all implementation），即训练一个 SVM 模型来将每个类别与所有其他类别分离。最终的预测基于具有最高值的决策函数。SVM 以良好的泛化能力和对噪声数据的鲁棒性而闻名【217】。此外，如第 2 章所述，ABSC 的特征向量通常包含大量特征，而 SVM 模型被认为能够很好地处理这些特征【102】。然而，找到适合的核函数通常是一项困难的任务【26】，并且需要手工设计特征以使模型表现良好【7】。</p>
<h3 id="4-2-2-Tree-Based"><a href="#4-2-2-Tree-Based" class="headerlink" title="4.2.2 Tree-Based"></a>4.2.2 Tree-Based</h3><p><strong>基于树的方法</strong>。基于树的方法是以可训练决策树模型【23】为基础的技术。决策树模型由类似树的结构组成，其中每个内部节点（或决策节点）表示基于特定特征 $\mathbf{x}$ 的条件检查，而每个叶节点表示特定的情感类别。给定特征向量 $\mathbf{x}$，从树的根节点开始，检查分裂条件。条件和 $\mathbf{x}$ 中的相应特征决定了下一步移动到哪个内部节点。沿树向下移动直到到达叶节点，该叶节点分配有特定的情感类别，决定了预测 $\hat{y}$。</p>
<p>决策树的一个显著优势是其可解释性。其决策规则通常易于人类理解，因此可以用于发现知识并获得新见解【139】。这些新见解还可以用于改进之前讨论的知识库。</p>
<p>虽然决策树模型在 ABSC 中并不特别流行，但仍有一些成功的应用示例。例如，文献【86】提出了一种增量决策树模型，在性能上优于之前讨论的 SVM 模型的实现。同样，文献【2】表明决策树在多个数据集上的表现优于包括 SVM 在内的其他模型。然而，对于其他问题，SVM 模型可能会优于决策树模型【6】。</p>
<p>决策树的主要问题是过拟合，这对于 ABSC 来说尤其突出，因为通常会使用大量特征。解决此问题的一种方法是使用随机森林模型，这是一种决策树的集成模型【22】。随机森林由大量的决策树模型组成。每棵树接收有限数量的特征和训练数据的自助采样（bootstrapped sample）来进行训练。通过随机采样数据和限制特征，单个决策树在特定特征或数据上的过拟合倾向较低。预测是通过聚合所有单个决策树模型的预测结果并进行多数投票来实现的。</p>
<p>文献【79】在 SemEval-2014 ABSC 任务中实现了随机森林模型，但在不同数据集上的结果参差不齐。类似的结果也见于文献【191】。其他基于树的方法的示例包括梯度提升树（Gradient Boosted Trees）【65】和极限树（Extra Trees）分类器【69】。文献【20】的比较研究表明，这些模型相比随机森林可能会提供轻微的性能改进。</p>
<h3 id="4-2-3-Deep-Learning"><a href="#4-2-3-Deep-Learning" class="headerlink" title="4.2.3 Deep Learning"></a>4.2.3 Deep Learning</h3><p>深度学习模型【72】革新了许多研究领域【178】，包括情感分析和 ABSC【50, 230】。大量研究致力于为各种类型的数据和学习任务开发深度学习模型。</p>
<p>深度学习模型的主要缺点之一是其高度难以解释。基本的机器学习模型，例如决策树和线性 SVM，可以提供一些有用的模型解释。然而，尽管已经有尝试解释深度学习模型预测的方法【55, 78】，这些黑箱方法在实践中仍被认为难以解释。此外，有效训练深度学习模型需要大量的计算资源。这是因为深度学习模型需要大量数据进行训练，而这些数据在 ABSC 领域并不总是可用。然而，随着深度学习研究的发展和公开数据量的增加【157–159】，深度学习模型因其卓越的预测性能而越来越受欢迎。</p>
<p>用于 ABSC 的深度学习模型包括但不限于：<strong>循环神经网络（Recurrent Neural Networks, RNN）</strong>、<strong>递归神经网络（Recursive Neural Networks）和卷积神经网络（Convolutional Neural Networks, CNN）</strong>。</p>
<p>![[Fig. 2. An illustration of a basic RNN model for ABSC..png]]</p>
<p><strong>循环神经网络（Recurrent Neural Network, RNN）</strong> 模型【92】近年来已成为 ABSC 模型最受欢迎的选择之一。RNN 模型是学习基于序列数据的强大工具【117】。它们在许多基于语言的学习任务中（包括 ABSC 以及各种其他基于序列的任务）取得了显著成果。</p>
<p>RNN 的基本模型如Fig 2 所示。在语言处理任务中，RNN 模型的核心思想是将单词序列依次输入到神经网络中。神经网络基于一个单词生成的隐藏状态被用作下一步的输入，从而使信息在序列中传递。相同的概念也可以用于处理图像序列、时间序列或其他类型的序列数据。</p>
<p>我们再次考虑一个包含方面 $a$ 和标签 $y$ 的记录 $R$。然而，与之前讨论的分类方法相比，我们现在假设数值特征以矩阵 $\mathbf{X} \in \mathbb{R}^{d_x \times n_x}$ 表示，其中 $d_x$ 表示使用的特征数量，$n_x$ 表示上下文中被考虑的单词数量。对于任何任务，给定输入矩阵 $\mathbf{X}$，通用的 RNN 模型可以定义为：</p>
<p>$$\mathbf{h}<em>t &#x3D; f(\mathbf{h}</em>{t-1}, \mathbf{x}_t)$$</p>
<p>其中：</p>
<p>• $\mathbf{h}_t \in \mathbb{R}^{d_h \times 1}$ 表示时间步 $t$ 的隐藏状态，</p>
<p>• $\mathbf{x}_t \in \mathbb{R}^{d_x \times 1}$ 表示时间步 $t$ 的输入向量，</p>
<p>• $f$ 表示用于更新隐藏状态的函数。</p>
<p>其中，$\mathbf{h}_t \in \mathbb{R}^{d_h}$ 是步骤 $t$ 的隐藏状态向量，$d_h$ 是隐藏状态向量的预定义维度；$\mathbf{x}_t \in \mathbb{R}^{d_x}$ 是矩阵 $\mathbf{X}$ 的第 $t$ 列，对于 $t &#x3D; 1, \dots, n_x$。在最基本的 RNN 形式中，函数 $f(.)$ 表示将向量 $\mathbf{h}_t$ 和 $\mathbf{x}_t$ 进行拼接（concatenation），然后通过一个由线性变换和非线性激活函数组成的基本神经网络模型。</p>
<p>因此，在每一步 $t$，前面单词的信息（包含在 $\mathbf{h}_{t-1}$ 中）与当前单词的信息（包含在 $\mathbf{x}<em>t$ 中）相结合。最后的隐藏状态向量 $\mathbf{h}</em>{n_x}$ 应包含从左到右处理的关于方面上下文的所有单词信息。最后的隐藏状态可以通过一个输出层生成标签预测。一个典型的输出层包括一个线性变换和一个 softmax 函数：</p>
<p>$$\mathbf{s} &#x3D; \text{softmax}(\mathbf{W}<em>f \cdot \mathbf{h}</em>{n_x} + \mathbf{b}_f),$$  </p>
<p>其中：</p>
<p>• $\mathbf{W}_f \in \mathbb{R}^{d_y \times d_h}$ 是最终层的可训练权重矩阵，</p>
<p>• $\mathbf{b}_f \in \mathbb{R}^{d_y}$ 是最终层的偏置向量，</p>
<p>• $\mathbf{s} \in \mathbb{R}^{d_y}$ 包含每个情感类别为正确标签的概率。</p>
<p>这些概率也可以解释为情感得分。在应用 softmax 函数后，可以通过选择具有最高情感得分或正确性概率的标签来生成预测。</p>
<p>虽然基础 RNN 模型在处理较短序列时效果很好，但在处理较长和更复杂的句子时会出现问题。由于神经网络的乘性特性，RNN 模型通常会严重受到梯度消失问题的影响，这意味着这些模型难以捕获长期依赖【19, 87】。</p>
<p>因此，更高级的 RNN 模型，例如长短期记忆网络（Long Short-Term Memory, LSTM）【88】和门控循环单元（Gated Recurrent Unit, GRU）【35】，通过引入一系列门控机制改进了函数 $f(.)$。这些门控机制允许信息在模型中流动，而不会丢失关键细节。这些 RNN 模型已被证明适用于许多不同的问题，并且已成为在 ABSC 中实现 RNN 的标准。进一步的改进可以通过双向 RNN（Bi-RNN）实现，该模型不仅从左到右处理单词，还可以从右到左处理。这种双向结构反转了信息流动的方向，允许保留单词序列两端的信息。</p>
<p>RNN 模型是多功能的模型，可应用于许多涉及序列数据的任务，包括 ABSC。文献【7】中实现了一种用于句子级 ABSC 的 LSTM 模型，并将其与用于酒店评论 ABSC 的 SVM 模型进行了比较。SVM 模型显著优于 RNN 模型，作者解释这主要归因于训练 SVM 模型时使用了丰富的手工设计特征向量。</p>
<p>相对而言，文献【166】中实现了一种分层 LSTM 模型，并使用 SemEval-2016【157】数据集进行评估，与其他深度学习架构进行了比较。该分层 LSTM 模型利用文档级信息执行句子级 ABSC。研究表明，即使未使用丰富的手工设计特征，该模型的性能与竞赛中的最佳模型相当。</p>
<p>在文献【187】中，提出了一种处理显式方面的新方法。两种 LSTM 模型分别用于建模目标词左右上下文的部分。该方法在基本 LSTM 模型的基础上有所改进，但与使用丰富特征和池化词嵌入的高级 SVM 模型相比，性能仍然相近【203】。然而，RNN 模型通常在更近期的任务中优于 SVM，特别是在 FiQA-2018 任务【126】中。</p>
<p>在最近的研究中，RNN 等深度学习模型在预测性能方面迅速超越了 SVM 模型。这种趋势在许多语言处理任务中都存在，部分原因是可用训练数据的增加。例如在 GLUE【206】和 SuperGLUE【205】基准测试中，所有表现最佳的模型均为深度学习方法。然而，如前所述，性能的提升需要付出巨大的计算代价，因为深度学习模型的训练通常需要比简单模型（如 SVM）更多的资源。</p>
<p>另一方面，深度学习模型可以节省设计手工特征的时间。因此，在为特定任务选择最佳模型时，除了基准数据集上的预测性能外，还需要考虑多种因素。例如，可能没有足够的计算资源，或者获取足够训练数据以正确训练深度学习模型的成本过高。另一方面，也可能没有足够的时间为高性能的 SVM 设计手工特征。</p>
<p>递归神经网络（Recursive Neural Network, RecNN）模型【71】是 RNN 模型的推广，使用类似树状结构处理单词。与 RNN 模型类似，RecNN 是通用模型，可以应用于多种任务。基本的 RecNN 模型如 Fig. 3 所示。</p>
<p>与 RNN 模型相似，RecNN 定义了一个函数 $f(.)$，用于组合输入向量。该函数在整个网络中共享，因此在每个处理步骤中都会使用。如图 3 所示，RecNN 树由叶节点（嵌入的输入向量）和内部节点（用蓝色表示）组成，在内部节点中使用函数 $f(.)$ 将向量组合。</p>
<p>![[Fig. 3. An illustration of a basic RecNN model for ABSC..png]]</p>
<p>对于一个具有两个子节点的内部节点，其输出可以定义为：</p>
<p>$$\mathbf{h}_p &#x3D; f(\mathbf{h}_l, \mathbf{h}_r),$$</p>
<p>其中：</p>
<p>• $\mathbf{h}_p$ 表示父节点的输出向量，</p>
<p>• $\mathbf{h}_l$ 和 $\mathbf{h}_r$ 分别表示左子节点和右子节点的向量，</p>
<p>• $f(.)$ 是用于组合子节点向量的函数。</p>
<p>其中，$\mathbf{h} \in \mathbb{R}^{d_x}$ 是内部节点的输出向量，$\mathbf{c}_1 \in \mathbb{R}^{d_x}$ 和 $\mathbf{c}_2 \in \mathbb{R}^{d_x}$ 是子节点的输出向量。通过迭代地组合单词嵌入和内部节点的输出向量，模型可以从单词中提取信息。在最后一步中，图 3 中的输出向量 $\mathbf{h}_4$ 应包含整个句子或上下文的信息。</p>
<p>虽然我们使用的是二叉树（ABSC 中最常见的类型）作为示例，但每个内部节点拥有三个或更多子节点的树也是可能的。然而，此时需要调整函数 $f(.)$ 以处理两个以上的输入。</p>
<p>在最基本的 RecNN 设置中，函数 $f(.)$ 采用标准神经网络的形式。然而，使用这一基本设置的 RecNN 模型可能会遇到与 RNN 相同的问题。因此，诸如 LSTM 模块之类的门控函数已经被调整为适配 RecNN 模型【186】。</p>
<p>使用 RecNN 模型相较于 RNN 的主要优势在于，模型不再局限于从左到右或从右到左顺序处理单词。输入的处理顺序取决于定义树的关系类型。树的结构也可以被设计为使模型按照原始顺序处理单词，这样它就等同于标准 RNN。然而，这也引出了这些模型的一个缺点：即如何定义树结构可能是一项困难的任务。</p>
<p>通常，RecNN 树是通过语言解析器构建的，解析器分析句子的结构和依赖关系，并对单词序列进行分解。解析是一个完全独立的研究领域，其中已经进行了大量研究【111】。现有多种解析器可用，而图 3 中的树是使用流行的 Stanford 神经网络解析器【33】生成的。</p>
<p>前面讨论的 RecNN 特性是适用于任何任务的通用属性。然而，也有针对 ABSC 提出的更专业化的 RecNN 模型。例如，树的构建可以专门针对 ABSC 任务进行调整。在文献【51】中，提出了一种用于处理显式方面的技术。文献【51】中的树是围绕与显式方面对应的目标单词或短语构建的。这意味着模型能够学习向方面前向传播情感信息。此外，与仅使用一个函数 $f(.)$ 不同，该模型实现了多种组合函数，模型根据输入向量和语言特性自适应地选择组合函数。这种专门为 ABSC 设计的 RecNN 模型被证明显著优于之前的 SVM 模型【101】。</p>
<p>Nguyen 和 Shirai【145】在这一思想的基础上进行了扩展，构建了一个结合了依存树和成分树的模型。此外，他们还扩展了对多种组合函数的使用。研究表明，该模型的性能优于文献【51】中提出的模型。然而，根据报告的结果，目前发现的 RecNN 模型的性能仍然不如其他深度学习模型。</p>
<p>卷积神经网络（Convolutional Neural Network, CNN）模型【116】是另一种广受欢迎的深度学习模型，常用于文本分析任务，例如情感分析和 ABSA【179, 221】。最初，CNN 模型被用于处理图像，采用三种不同的层类型：卷积层、池化层和全连接层。Fig. 4 展示了语言处理背景下这些层的基本 CNN 模型。</p>
<p>• <strong>卷积层（Convolutional Layer）</strong> 通常被描述为一个滤波器，滑过输入数据矩阵，并对窗口内的值进行线性组合，从而生成特征图。</p>
<p>• <strong>池化层（Pooling Layer）</strong> 可用于减少输出的维度，并通过总结卷积层获得的信息来提高泛化能力。常见的池化方法包括最大池化（Max Pooling）和平均池化（Average Pooling）。</p>
<p>• <strong>全局池化层（Global Pooling Layer）</strong> 通常在最终层之前使用，用于将特征矩阵转换为单个向量。</p>
<p>最终，该向量通过全连接层（Fully-Connected Layers）进行处理，以生成正确的输出。CNN 模型因其高效性和结构灵活性而在文本分析领域表现出色。</p>
<p>![[Fig. 4. An illustration of a basic CNN model for ABSC..png]]</p>
<p>前述模型层构成了可用于多种任务的通用架构。因此，CNN 模型也被用于 ABSC。在文献【142】中，研究表明，CNN 模型在 ABSC 中的性能优于 SVM 模型。</p>
<p>文献【167】中实现了一种专门设计用于 ABSC 的 CNN，通过引入目标嵌入（Target Embeddings）明确建模方面。该方法将方面嵌入与输入向量拼接后作为 CNN 的输入。结果显示，这种方法在所用数据集上表现与最佳模型相当。</p>
<p>另一种方法由文献【221】提出，使用方面嵌入，但以非线性门控机制的形式插入到卷积层和池化层之间。该模型生成了高度准确的预测，优于许多其他模型，包括随机森林【79】、RecNN 模型【51, 145】，甚至一些基于注意力的深度学习模型（见 4.2.4 小节讨论）。</p>
<p>文献【227】进一步扩展和改进了该门控 CNN，通过在损失函数中引入语言正则化扩展进行优化。尽管该模型在 SemEval-2014 数据集上接近于最佳性能，但仍被一种混合模型【106】超越，该混合模型将在 4.3.1 小节中讨论。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/deepLearning/" rel="tag"><i class="fa fa-tag"></i> deepLearning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/45e08570.html" rel="prev" title="基于超图的多模态情绪识别">
                  <i class="fa fa-angle-left"></i> 基于超图的多模态情绪识别
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/c48587a3.html" rel="next" title="Opinion Word Expansion and Target Extraction through Double Propagation">
                  Opinion Word Expansion and Target Extraction through Double Propagation <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><span class="exturl" data-url="aHR0cHM6Ly9iZWlhbi5taWl0Lmdvdi5jbg==">浙ICP备 2023011468号-1 </span>
      <img src="https://images-a2q.pages.dev/file/ab4ebf9b9723073c81a21.png" alt="">
  </div>
  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Joey</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>Word count total: </span>
    <span title="Word count total">140k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>Reading time total &asymp;</span>
    <span title="Reading time total">8:30</span>
  </span>
</div>
  <div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZw==">NexT.Gemini</span>
  </div>

    </div>
  </footer>

  
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.28/fancybox/fancybox.umd.js" integrity="sha256-ytMJGN3toR+a84u7g7NuHm91VIR06Q41kMWDr2pq7Zo=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.6.1/mermaid.min.js","integrity":"sha256-mm3Re3y7xlvh+yCD+l/Zs1d+PU0AEad93MkWvljfm/s="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"http://example.com/posts/cc20b26.html"}</script>
  <script src="/js/third-party/quicklink.js"></script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":180,"height":300},"mobile":{"show":false},"react":{"opacity":1},"log":false});</script></body>
</html>
